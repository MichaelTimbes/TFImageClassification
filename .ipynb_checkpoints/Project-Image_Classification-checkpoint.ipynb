{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Michael Timbes\n",
    "#Purpose:\n",
    "#Image_Classification Based on Logistic classification model. Single hidden layer, does not use convolutional layers\n",
    "#does not use pooling. May not be accurate for use when non-binary classification is needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL\n",
    "#Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#File import\n",
    "from os import listdir\n",
    "from PIL import Image as PImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Path of test images\n",
    "path = ('testimgs')\n",
    "#Dimension of image\n",
    "IMAG_X = 10\n",
    "IMAG_Y = 12\n",
    "\n",
    "#Trainig rate alpha\n",
    "alpha = 0.5\n",
    "\n",
    "#Number of inputs defined\n",
    "NUM_IN = (IMAG_X * IMAG_Y)\n",
    "\n",
    "#Number of classifications\n",
    "y_out_clss = 2"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 35,
>>>>>>> 464d86943259b0f1925bcf7e46392fe57d4298e7
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Import data\n",
    "def ImportImages(path):\n",
    "    \"\"\"\n",
    "    def ImportImages(path):\n",
    "    ________________________________________________________________\n",
    "    Function Outline:\n",
    "    1. Loads list of images from the path variable (type string).\n",
    "    2. Iterates through directory loads image into I/O file stream.\n",
    "    3. Converts file to LA grey scale.\n",
    "    4. Casts the image data into Numpy array.\n",
    "    5. Returns Numpy array object.\n",
    "    \"\"\"\n",
    "\n",
    "    imagesList = listdir(path)\n",
    "    \n",
    "    loadedImages = []\n",
    "    \n",
    "    for image in imagesList:\n",
    "        \n",
    "        img = PImage.open(path +'/'+ image).convert('LA')\n",
    "        img.load()\n",
    "        img.flatten()\n",
    "        loadedImages = np.asarray( img, dtype=\"int32\" )\n",
    "    #Add reshape code here:\n",
    "    return loadedImages"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 52,
>>>>>>> 464d86943259b0f1925bcf7e46392fe57d4298e7
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'flaten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ec6cd5faaaa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImportImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-b6c503a43e3d>\u001b[0m in \u001b[0;36mImportImages\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflaten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mloadedImages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int32\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'flaten'"
     ]
    }
   ],
   "source": [
    "train_X = ImportImages(path)\n",
    "train_X[1]"
=======
     "data": {
      "text/plain": [
       "(226, 223, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = ImportImages(path)"
>>>>>>> 464d86943259b0f1925bcf7e46392fe57d4298e7
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#The x_input_layer and y_output_layer values are placeholders for the model that accept the flattened image (x) \n",
    "#and then the ouput of theclassifications (y). \n",
    "#\n",
    "x_input_layer = tf.placeholder(tf.float32, shape= [None, NUM_IN])\n",
    "y_output_layer = tf.placeholder(tf.float32, shape= [None, y_out_clss])\n",
    "\n",
    "\n",
    "#The vectors for weights and b- the bias will be defined as variables for training later.\n",
    "\n",
    "Weights = tf.Variable(tf.zeros([NUM_IN, y_out_clss]))\n",
    "b = tf.Variable(tf.zeros([y_out_clss]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Outline of the Model:\n",
    "The $X_{input}$ variable is the input layer which accepts a flat array of pixel values that are grey scale. The $W$ varible is the matrix that contains the weight values for the input features. The $b$ is the bias associated with the layers (in this case only a single layer). The $Y_{model}$ is the final layer and will be the product of the input features and weights with bias added expected range is: $0 \\geq Y \\geq 1$. <br>\n",
    "$X_{input} \\cdot W + b = Y_{model}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Outline of the model based on the probabilities calculated plus bias values.\n",
    "\n",
    "y_model = tf.matmul(x_input_layer, Weights) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Used:\n",
    "Logistic regression model: $$hyp(X) =  (\\frac{1}{e^{-\\theta^{T}X}} )^{-1}$$ <br>\n",
    "Cost Function: For all $j \\in |\\theta|$ and $x \\in X$ $$\\theta_{j} = \\theta_{j} -\\alpha \\sum_{i=1}^{m}(hyp(x^{i})-y^{i})x^{i}_{j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#This is where the train steps happens. Cross entropy is calculated by running the current model and then running \n",
    "#gradient decent. Training step stores results from the gradient descent minimizing cost function (cross_entropy).\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_output_layer, logits = y_model))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(alpha).minimize(cross_entropy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Init session and global variables\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Training block\n",
    "#for i in range(100): #Outside train loop\n",
    "   # for start in range(0, len())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
