{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Michael Timbes\n",
    "#Purpose:\n",
    "#Image_Classification Based on Logistic classification model. Single hidden layer, does not use convolutional layers\n",
    "#does not use pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "#File import\n",
    "from os import listdir\n",
    "from os import path as opath\n",
    "from PIL import Image as PImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Path of test images\n",
    "path = ('train_set')\n",
    "#Dimension of image\n",
    "IMAG_X = 10\n",
    "\n",
    "#Trainig rate alpha\n",
    "alpha = 0.5\n",
    "\n",
    "#Number of inputs defined\n",
    "NUM_IN = (IMAG_X**2)\n",
    "\n",
    "#Number of classifications\n",
    "y_out_clss = 2\n",
    "\n",
    "#Size of batch\n",
    "BatchSize = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Import data\n",
    "def ImportImages(path):\n",
    "    \"\"\"\n",
    "    def ImportImages(path):\n",
    "    USES VARIABLES: IMAG_X, IMAG_Y, expects these to be set already.\n",
    "    If prefered, edit code to pass them as arguments.\n",
    "    ________________________________________________________________\n",
    "    Function Outline:\n",
    "    1. Loads list of images from the path variable (type string).\n",
    "    2. Iterates through directory loads image into I/O file stream.\n",
    "    3. Converts file to LA grey scale and resizes.\n",
    "    4. Casts the image data into Numpy array.\n",
    "    5. Returns Numpy array object.\n",
    "    \"\"\"\n",
    "\n",
    "    imagesList = listdir(path)\n",
    "    \n",
    "    loadedImages = []\n",
    "    \n",
    "    loadedLabels = []\n",
    "  \n",
    "    new_size = IMAG_X, IMAG_X\n",
    "    \n",
    "    for image in imagesList:\n",
    "     \n",
    "        img = PImage.open(path +'/'+ image)\n",
    "        #Pull file name from current image- use it as a label\n",
    "        loadedLabels.append(opath.splitext(image)[0])\n",
    "        img.load()\n",
    "        #Resize step- ensures that all images follow.\n",
    "        img.thumbnail(new_size, PImage.ANTIALIAS )\n",
    "        loadedImages = np.asarray( img, dtype=\"int32\" )\n",
    "    return loadedImages, loadedLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def shape_up_X(train_X, IMAG_X):\n",
    "    \"\"\"\n",
    "    shape_up_X(train_X, IMAG_X):\n",
    "    \n",
    "    Expects a 3D numpy array train_X with \n",
    "    dimensions (width_val, height_val, image#).\n",
    "    Must be square matrix with and height being\n",
    "    equal.\n",
    "    Returns new_X which is a reshaped train_X\n",
    "    of type numpy array.\n",
    "    ____________________________________\n",
    "    Dimensions are (pixels, image#). The\n",
    "    size of the pixels dimension is taken from\n",
    "    the square of IMAG_X. The number of images are found\n",
    "    by taking the length of the third column.\n",
    "    \"\"\"\n",
    "    num_exs = len(train_X[0,0,:])\n",
    "    new_X = train_X.reshape((IMAG_X**2, num_exs ))\n",
    "    new_X.flatten('C')\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_batch(train_X, train_Y, start, batch_size):\n",
    "    \"\"\"\n",
    "    def create_batch(train_X, batch_size):\n",
    "    __________________________________________\n",
    "    Function Outline:\n",
    "    1.Creates training subset of train_X and train_Y\n",
    "    \"\"\"\n",
    "    batch_x = train_X[:,start:batch_size]\n",
    "    batch_y = train_Y[start:batch_size]\n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_Y = ImportImages(path)\n",
    "Num_to_Train = len(train_X[0,0,:])\n",
    "train_X = shape_up_X(train_X,IMAG_X)\n",
    "Num_to_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#The x_input_layer and y_output_layer values are placeholders for the model that accept the flattened image (x) \n",
    "#and then the ouput of theclassifications (y). \n",
    "#\n",
    "x_input_layer = tf.placeholder(tf.float32, shape= [None,NUM_IN])\n",
    "y_output_layer = tf.placeholder(tf.float32, shape= [None, y_out_clss])\n",
    "\n",
    "\n",
    "#The vectors for weights and b- the bias will be defined as variables for training later.\n",
    "\n",
    "Weights = tf.Variable(tf.zeros([NUM_IN, y_out_clss]))\n",
    "b = tf.Variable(tf.zeros([y_out_clss]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Outline of the model based on the probabilities calculated plus bias values.\n",
    "\n",
    "y_model = tf.matmul(x_input_layer, Weights) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#This is where the train steps happens. Cross entropy is calculated by running the current model and then running \n",
    "#gradient decent. Training step stores results from the gradient descent minimizing cost function (cross_entropy).\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_output_layer, logits = y_model))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(alpha).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Init session and global variables\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (100, 0) for Tensor 'Placeholder_12:0', which has shape '(?, 100)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-017ffcee0ae8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m#print(batch_x[1], batch_y[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx_input_layer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_output_layer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\micha\\Anaconda3\\envs\\tensorflow_35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   1586\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1587\u001b[0m     \"\"\"\n\u001b[1;32m-> 1588\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\micha\\Anaconda3\\envs\\tensorflow_35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3830\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3831\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3832\u001b[1;33m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\micha\\Anaconda3\\envs\\tensorflow_35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\micha\\Anaconda3\\envs\\tensorflow_35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    942\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 944\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    945\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (100, 0) for Tensor 'Placeholder_12:0', which has shape '(?, 100)'"
     ]
    }
   ],
   "source": [
    "#Training block\n",
    "for i in range(1): #Outside train loop\n",
    "    end = BatchSize\n",
    "    for start in range(0,Num_to_Train,BatchSize):\n",
    "        end = start + BatchSize\n",
    "        batch_x, batch_y = create_batch(train_X, train_Y, start, end)\n",
    "        #print(batch_x[1], batch_y[1])\n",
    "    train_step.run(feed_dict={x_input_layer: batch_x[:,start:end], y_output_layer: batch_y[start:end]}) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
