{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Michael Timbes\n",
    "#Purpose:\n",
    "#Image_Classification Based on Logistic classification model. Single hidden layer, does not use convolutional layers\n",
    "#does not use pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "#File import\n",
    "from os import listdir\n",
    "from os import path as opath\n",
    "from PIL import Image as PImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Path of train images\n",
    "train_path = ('trainset2')\n",
    "#Path of test images\n",
    "test_path = ('testset2')\n",
    "\n",
    "#Dimension of image\n",
    "WIDTH = 100\n",
    "HEIGHT = 100\n",
    "\n",
    "#Trainig rate alpha\n",
    "alpha = 0.1\n",
    "\n",
    "#Number of inputs defined\n",
    "NUM_IN = WIDTH * HEIGHT\n",
    "\n",
    "#Number of classifications\n",
    "y_out_clss = 2\n",
    "keyA = 'face' #True Class\n",
    "keyB = 'notface' #False Class\n",
    "\n",
    "#Size of batch\n",
    "BatchSize = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Import data\n",
    "def ImportImages(path, width, height):\n",
    "    \"\"\"\n",
    "    Images must be in RGB space.\n",
    "    ________________________________________________________________\n",
    "    Function Outline:\n",
    "    1. Loads list of images from the path variable (type string).\n",
    "    2. Iterates through directory loads image into I/O file stream.\n",
    "    3. Converts file Numpy array.\n",
    "    4. Reads labels and converts to binary class.\n",
    "    5. Returns Numpy array objects for images and labels.\n",
    "    \"\"\"\n",
    "\n",
    "    loadedImages = []\n",
    "    loadedLabels = []\n",
    "    originalLabels = []\n",
    "    \n",
    "    imagesList = listdir(path)\n",
    "  \n",
    "    new_size = width, height\n",
    "    \n",
    "    for image in imagesList:\n",
    "        if not(\".DS_Store\" in path +'/'+ image): #Issue in Mac File System\n",
    "            img = PImage.open(path +'/'+ image)\n",
    "            label = opath.splitext(image)[:]\n",
    "        \n",
    "            # Pull file name from current image- use it as a label\n",
    "            originalLabels.append(label[0])\n",
    "            img.load()\n",
    "\n",
    "            # Resize step- ensures that all images follow.\n",
    "            #img.thumbnail(new_size, PImage.ANTIALIAS )\n",
    "            #img.convert('1')\n",
    "            #img.resize(new_size)\n",
    "            loadedImages.append(np.asarray( img, dtype=\"int32\" ))\n",
    "        \n",
    "    # Convert to Binary Classification.\n",
    "    for originalLabel in originalLabels:\n",
    "        if keyA in originalLabel and not(keyB in originalLabel):\n",
    "            loadedLabels.append([1, 0])\n",
    "        else:\n",
    "            loadedLabels.append([0, 1])\n",
    "    \n",
    "    return np.asarray(loadedImages), np.asarray(loadedLabels), originalLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def shape_up_(data, width):\n",
    "    \"\"\"\n",
    "    Expects a NUM_IN * NUM_IN sized picture.\n",
    "    Changes the shape to be (N,NUM_IN**2).\n",
    "    \"\"\"\n",
    "    num_exs = len(data[:,0,0,0])\n",
    "    new_X = np.zeros((num_exs,width**2 * 3))\n",
    "    for i in range(0,num_exs):\n",
    "        new_X[i,:] = data[i,:,:,:].reshape((1,width**2 * 3))\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def out_class(Y):\n",
    "    \"\"\"\n",
    "    Matches Class with input vector.\n",
    "    \"\"\"\n",
    "    return np.asarray([keyB if label == 1 else keyA for label in Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Preparation\n",
    "* Import Images\n",
    "* Reshape Images\n",
    "* Final Array Should Be:\n",
    "$$train_{x} = \\begin{pmatrix} \n",
    "[Picture Array_{MxM}] , & [Num Examples]\\\\\n",
    "\\end{pmatrix}$$\n",
    "$$train_{y} = \\begin{pmatrix} \n",
    "Class_{1} & Class_{2} & \\cdots & Class_{n}\\\\\n",
    "\\end{pmatrix}$$\n",
    "Where the $Class_{n}$ is either a 1 for the true class or 0 for the false class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 100, 100, 3)\n",
      "Number of examples:  18\n",
      "(18, 30000)\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "['face_0', 'face_1', 'face_2', 'face_90', 'face_91', 'face_92', 'face_93', 'face_94', 'notface_0', 'notface_1', 'notface_2', 'notface_3', 'notface_4', 'notface_95', 'notface_96', 'notface_97', 'notface_98', 'notface_99']\n"
     ]
    }
   ],
   "source": [
    "#Training Data Preparation\n",
    "training_images, training_labels, training_original = ImportImages(train_path, WIDTH, HEIGHT)\n",
    "print(training_images.shape)\n",
    "m = len(training_images)\n",
    "print(\"Number of examples: \", m)\n",
    "training_images = shape_up_(training_images,WIDTH)\n",
    "# Showing the shape of train_X\n",
    "print(training_images.shape)\n",
    "print(training_labels)\n",
    "print(training_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 30000)\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "['face_11', 'face_12', 'face_13', 'notface_17', 'notface_18', 'notface_19']\n"
     ]
    }
   ],
   "source": [
    "#Testing Data Preparation \n",
    "test_images, test_labels, test_original = ImportImages(test_path, WIDTH, HEIGHT)\n",
    "test_images = shape_up_(test_images, WIDTH)\n",
    "print(test_images.shape)\n",
    "print(test_labels)\n",
    "print(test_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Build Logistic Model\n",
    "## Input Layer\n",
    "Dimension for $X$ is $1xN$. For Tensorflow, x_input_layer as a placeholder must be at least a 1-D vector but can support $MxN$ so a 'None' type is used to be more dynamic. To ensure the matrix multiplication is not an issue be sure that the weight layer and X layer are $Nx1$ and $1xN$. \n",
    "\\begin{equation}\n",
    "    \\begin{pmatrix}\n",
    "    x_{0} \\\\\n",
    "    x_{1} \\\\\n",
    "    \\vdots \\\\\n",
    "    x_{n}\n",
    "    \\end{pmatrix}\n",
    "\\end{equation}\n",
    "## Weights\n",
    "\\begin{equation}\n",
    "    \\begin{pmatrix}\n",
    "    \\theta_{0} & \\theta_{1} & \\cdots & \\theta{n} \\\\\n",
    "     & & \\vdots & \\\\\n",
    "     \\theta_{0} & \\theta_{1} & \\cdots & \\theta{n} \\\\\n",
    "    \\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "## Output Layer\n",
    "Below is for multi-class in this application where there are $\\theta_{n}$ classes.\n",
    "\\begin{equation}\n",
    "h_{\\theta}(x) = \n",
    "\\begin{pmatrix}\n",
    "    \\theta_{0} & \\theta_{1} & \\cdots & \\theta{n} \\\\\n",
    "     & & \\vdots & \\\\\n",
    "     \\theta_{0} & \\theta_{1} & \\cdots & \\theta{n} \\\\\n",
    "    \\end{pmatrix}\n",
    "    \\begin{pmatrix}\n",
    "    x_{0} \\\\\n",
    "    x_{1} \\\\\n",
    "    \\vdots \\\\\n",
    "    x_{n}\n",
    "    \\end{pmatrix} =\n",
    "     \\begin{pmatrix}\n",
    "    y_{0} \\\\\n",
    "    y_{1} \\\\\n",
    "    \\vdots \\\\\n",
    "    y_{m}\n",
    "    \\end{pmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#The x_input_layer and y_output_layer values are placeholders for the model that accept the flattened image (x) \n",
    "#and then the ouput of theclassifications (y). \n",
    "#\n",
    "x_input_layer = tf.placeholder(tf.float32, shape=[None, NUM_IN * 3]) \n",
    "y_ = tf.placeholder(tf.float32, shape= [None, y_out_clss])\n",
    "\n",
    "\n",
    "#The vectors for weights and b- the bias will be defined as variables for training later.\n",
    "\n",
    "Weights = tf.Variable(tf.zeros([NUM_IN * 3, y_out_clss]))\n",
    "b = tf.Variable(tf.zeros([y_out_clss]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Outline of the model based on the probabilities calculated plus bias values.\n",
    "\n",
    "y = tf.matmul(x_input_layer, Weights) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Cross Entropy\n",
    "## Cost Function\n",
    "\\begin{equation}\n",
    "J(\\theta)= -\\frac{1}{m}\\sum_{i=1}^{m} y_{i}log(h_{\\theta}(x_{i}))+\n",
    "\t\t\t\t\t\t\t\t\t  (1-y_{i})log(1-h_{\\theta}(x_{i}))\n",
    "\\end{equation}\n",
    "## Minimize Cost-Gradient Descent\n",
    "\\begin{equation}\n",
    "\\theta_{j} = \\theta_{j}-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}\\left((h_{\\theta}(x_{i})-y_{i})X_{ji}\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#This is where the train steps happens. Cross entropy is calculated by running the current model and then running \n",
    "#gradient decent. Training step stores results from the gradient descent minimizing cost function (cross_entropy).\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(alpha).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Init session and global variables\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#Design batch variables- ensure dimension\n",
    "#x_batch = np.ones((1, NUM_IN))\n",
    "#y_batch = np.ones((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "#Training Block:\n",
    "for i in range(1000): #Outside train loop\n",
    "     for j in range(0,m):\n",
    "            sess.run(train_step,feed_dict={x_input_layer: training_images, y_: training_labels})\n",
    "print(\"DONE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[0 0 0 1 1 1]\n",
      "OUTPUT:  ['face' 'face' 'face' 'notface' 'notface' 'notface']\n",
      "ACTUAL:  ['face_11', 'face_12', 'face_13', 'notface_17', 'notface_18', 'notface_19']\n"
     ]
    }
   ],
   "source": [
    "#Test Block:\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(accuracy.eval(feed_dict={x_input_layer: test_images, y_: test_labels}))\n",
    "y_out = sess.run(tf.argmax(y,1),feed_dict={x_input_layer: test_images})\n",
    "\n",
    "# Ouput of Tests\n",
    "print(y_out)\n",
    "classes = out_class(y_out)\n",
    "print(\"OUTPUT: \", classes)\n",
    "print(\"ACTUAL: \", test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
